{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tm218QYpEssV"
   },
   "source": [
    "TextGen with Markov chains and weirdly compatible datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## часть 1: марковские цепи своими руками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**подготовительный этап**\n",
    "\n",
    "сначала нам нужно задать некоторый текст, на основе которого мы будем генерировать новые предложения. Создадим документ, в который добавим текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! touch \"text.txt\" # это команда для linux-подобных систем, для Win попробуйте ni (в PowerShell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "следующей командой добавим текст (например, о приготовлении кофе) в документ, сразу в терминале"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"This is a manual brewing process where grounds are soaked in hot water then pressed down to the bottom of the coffee maker by pushing down on a plunger. A French press brews the fullest-flavored cup of coffee, thanks to its stainless steel filter. While a paper filter soaks up the coffee's natural oils (where much of the flavor is held), the press' built-in metal filter allows the oils through. Note: Because a French press does not use a paper filter, there will be a little coffee sediment at the bottom, so leave that last sip in the mug.\" >> text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tail: option used in invalid context -- 1\n"
     ]
    }
   ],
   "source": [
    "! tail -1 text.txt # теперь посмотрим на текст: head покажет начало документа, tail - конец"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**основной этап**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишем питонскую функцию которая генерирует новые последовательности слов из заданнного текста\n",
    "\n",
    "\n",
    "def markov_text(input_text):\n",
    "    \"\"\" This func opens a file, reads its contents and \n",
    "    creates a dictionary of words in the markov_gen variable\n",
    "    based on the number of words a user wants to generate.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    import nltk\n",
    "    import ssl\n",
    "\n",
    "    try:\n",
    "        _create_unverified_https_context = ssl._create_unverified_context\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "\n",
    "    nltk.download(\"punkt\", quiet=True)\n",
    "    from nltk import word_tokenize\n",
    "\n",
    "\n",
    "    data_sample = input_text\n",
    "\n",
    "    text_data = open(data_sample, 'r').read()\n",
    "    text_data = ''.join([i for i in text_data]).replace(\"\\\\n\", \"\").replace(\"\\n\", \"\")\n",
    "    text_data = word_tokenize(text_data)\n",
    "    # we made a list out of words \n",
    "    \n",
    "    index = 1 # задали первый индекс\n",
    "    markov_gen = {} # пустой словарь, в него положим ключи(слова) и значения (слова, рядом с ними)\n",
    "    word_count = int(input('select the number of words you want to generate ')) \n",
    "    # задали кол-во итераций: сколько слов будет в итоговом тексте\n",
    "\n",
    "    for character in text_data[index:]: \n",
    "        # для каждого в списке слов датасета, начиная со второго слова\n",
    "        \n",
    "        key = text_data[index-1] # ключ - это предыдущее слово\n",
    "        if key in markov_gen:\n",
    "            markov_gen[key].append(character)\n",
    "            # если слово уже в ключах, добавляем к нему в лист значений новое\n",
    "        else:\n",
    "            markov_gen[key] = [character] # в ином создаем лист для значений\n",
    "        index += 1\n",
    "\n",
    "    character1 = random.choice(list(markov_gen.keys()))\n",
    "    # превращаем ключи в лист, рандомчойсом выбираем начало\n",
    "    message = character1.capitalize()\n",
    "\n",
    "    while len(message.split(' ')) < word_count: # пока слов меньше лимита итераций\n",
    "        character2 = random.choice(markov_gen[character1]) \n",
    "        # рандомно выбираем слово из значений, ключ - предыдущее слово\n",
    "        character1 = character2 \n",
    "        message += ' ' + character2\n",
    "        \n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "теперь можно применить функцию к текстовому документу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select the number of words you want to generate 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"A French press ' built-in metal filter . Note : Because a paper filter , thanks to\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_text(\"text.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы сгенерировали новое предложение длиной в 17 слов, на тему приготовления кофе. *(пока что они выглядят странно, это нормально)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPkg1jhEA59z"
   },
   "source": [
    "## часть 2 : попробуем генерировать истории\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3EPFfNUOGXN9",
    "outputId": "e625da2d-c07f-4edb-8769-0ee25c59c35c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    }
   ],
   "source": [
    "! pip3 install markovify # установим библиотеку для марковских цепей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "frwNgg5JGfyU"
   },
   "outputs": [],
   "source": [
    "import markovify "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "попробуем [на текстах басен Крылова](https://github.com/sjut/DPO_Materials/blob/master/%D0%94%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B8%20%D1%81%D1%81%D1%8B%D0%BB%D0%BA%D0%B8/basni.zip):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним текстовый файл, откроем его\n",
    "\n",
    "with open(\"test_basni.txt\", encoding = \"utf-8\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print(data) # здесь можно посмотреть на содержимое файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhXuA6xcG_gg",
    "outputId": "bb075859-49c8-4bf2-d8f6-1d92b16c9451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ударили в землю лбом; «Изрядно, — с высоты: От первых жди от них разборы И поплатился он ослабевал И споры, кому и нежен, и — сказать неложно, Тебя без сил, Валяется в старости и протяжно: Во всем лесу у нас была царь-птица!» Вещуньина с высоты: От первых жди от них разборы И на лад нейдет.\n",
      "Поверишь ли, в смычки, дерут, а толку нет.\n",
      "Уж сколько раз твердили миру, Что лесть гнусна, вредна; но только замолчишь, то жду я, не сводит И сели на лад нейдет.\n",
      "Поверишь ли, в сердце льстец всегда отыщет уголок.\n"
     ]
    }
   ],
   "source": [
    "initial_letters = markovify.Text(data, state_size =1) \n",
    "# последний аргумент регулирует размер повторяющихся цепочек\n",
    "\n",
    "for i in range(4): # задаем количество предложений \n",
    "    print(initial_letters.make_sentence(), sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем задавать и количество слов в предложении, и количество предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WjoJ9UCzHDom",
    "outputId": "8336397a-0c55-4dcd-ec54-b44df6903682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ведь вы не стыдись!\n",
      "Ведь вы не так сладко, чуть дыша: «Голубушка, как сидеть.\n",
      "Расселись, начали Квартет; Он все-таки на шум их прилететь.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3): # кол-во предложений\n",
    "    print(initial_letters.make_short_sentence(80), sep = \"\\n\") # кол-во слов в предложении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Il6uzY5pBBrM"
   },
   "source": [
    "## часть 3: что делать дальше\n",
    "\n",
    "Попробуйте сгенерировать интересные тексты из материалов, которые интересны Вам: художественная литература, новости, статьи, и  тд. Как правило, чем больше изначального текста, тем больше вероятность, что генерированный текст будет выглядеть естественно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install markovify --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Strugackiy.txt\", encoding = \"utf-8\") as f:\n",
    "    Strugackiy = f.read()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Huxley.txt\", encoding = \"utf-8\") as f:\n",
    "    Huxley = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = markovify.Text(Strugackiy)\n",
    "model_b = markovify.Text(Huxley)\n",
    "\n",
    "model_combo = markovify.combine([ model_a, model_b ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сидоров перешагнул через Валькенштейна и подошел к оператору: — Пойдемте.\n",
      "И опять Кондратьев не стал переспрашивать: он решил, что Бернарду и впрямь, пожалуй, влили спирту в кровезаменитель. — Фосген, хлорпикрин, йодуксусный этил, дифенилцианарсин, слезоточивый газ, иприт.\n",
      "В техническом аспекте проще простого было бы зарыть или сжечь. — И вы такой же, как все.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(model_combo.make_sentence(), sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "И они тянут, тянут, тянут с высадкой… Почему они не могут? — проворчал Белов.\n",
      "— Товарищ, — сказал диспетчер сквозь зубы.\n",
      "Он вспомнил, что это очень противно, когда тебе плачут в жилетку.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(model_combo.make_short_sentence(90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Markov Chains TexGen",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
